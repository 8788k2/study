# LSTMì„ ì´ìš©í•œ ì‹œê³„ì—´ ì˜¨ë„ ë³€í™” ì˜ˆì¸¡ í•™ìŠµ


## í•™ìŠµ ëª©í‘œ
ìŠ¤ë§ˆíŠ¸ì—ì–´ì»¨ì—ì„œ ìˆ˜ì§‘ëœ LOG ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ, ì‹¤ë‚´ì˜¨ë„ ì˜ˆì¸¡ì— ìœ ì˜ë¯¸í•œ featureë¥¼ ì„ ì •í•˜ê³  ì •í™•ë„ ë†’ì€ LSTM ì˜ˆì¸¡ ëª¨ë¸ì„ í•™ìŠµí•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•œë‹¤. 

ì´ë¥¼ í†µí•´ í•™ìŠµëœ LSTMì˜ íˆë“  ìŠ¤í…Œì´íŠ¸ê°€ ì‹œê°„ì— ë”°ë¼ ë³€í™”í•˜ëŠ” ì—´ë¶€í•˜(dynamic thermal load) ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ë‚´í¬í•  ìˆ˜ ìˆì„ ê²ƒì´ë¼ëŠ” ê°€ì •ì„ ë°”íƒ•ìœ¼ë¡œ í•œë‹¤. 

ê¶ê·¹ì ìœ¼ë¡œ ì´ íˆë“  ìŠ¤í…Œì´íŠ¸ë¥¼ ê°•í™”í•™ìŠµ í™˜ê²½ì—ì„œ ìƒíƒœ(state)ì˜ ì¼ë¶€ë¡œ í™œìš©í•¨ìœ¼ë¡œì¨, ì—´ë¶€í•˜ì— ëŒ€í•œ ì •ë³´ ë¶€ì¡±ìœ¼ë¡œ ë°œìƒí•  ìˆ˜ ìˆëŠ” ì„œë¸Œì˜µí‹°ë©€(suboptimal)í•œ ì œì–´ ì •ì±…ì„ ì™„í™”í•˜ê³ ì í•œë‹¤.


## LOG ë°ì´í„° í˜•íƒœ
![log](images/LOGë°ì´í„°%20ì˜ˆì‹œ.png)

## ì…ë ¥ ë° ì¶œë ¥ ë°ì´í„° êµ¬ì¡° ìš”ì•½

### ì…ë ¥ ë°ì´í„° (input)

| ë³€ìˆ˜ëª…      | ì˜ë¯¸                              | ì‹œê°„ ë‹¨ìœ„ | ì‹œê³„ì—´ ê¸¸ì´ | 
|-------------|-----------------------------------|--------------|-------------------|
| Thmo On     | ëƒ‰ë°©ê¸° ì—°ì† ê°€ë™ ì‹œê°„ (ì´ˆ)         | 5ì´ˆ         | 60ê°œ (5ë¶„)  | 
| Tcon        | í¬ë§ ì˜¨ë„ (Â°C)                     | 5ì´ˆ         | 60ê°œ (5ë¶„)  | 
| Frun        | í’ëŸ‰ ì„¸ê¸°                          | 5ì´ˆ         | 60ê°œ (5ë¶„)  | 
| Tpip_in     | ì‹¤ë‚´ê¸°ë¡œ ë“¤ì–´ê°€ëŠ” ëƒ‰ë§¤ ì˜¨ë„ (Â°C)   | 5ì´ˆ         | 60ê°œ (5ë¶„)  | 
| Tpip_out    | ì‹¤ë‚´ê¸°ì—ì„œ ë‚˜ì˜¤ëŠ” ê³µê¸° ì˜¨ë„ (Â°C)   | 5ì´ˆ         | 60ê°œ (5ë¶„)  | 
| Tod         | ì™¸ê¸° ì˜¨ë„ (Â°C)                     | 5ì´ˆ         | 60ê°œ (5ë¶„)  | 
| Power       | ì§€ë‚œ 1ë¶„ê°„ ì‚¬ìš© ì „ë ¥ (kWh ë“±)      | 5ì´ˆ         | 60ê°œ (5ë¶„)  | 
| Tbdy        | ì‹¤ë‚´ ì˜¨ë„ (Â°C)                     | 5ì´ˆ         | 60ê°œ (5ë¶„)  | 

> ì´ ì…ë ¥ í˜•íƒœ: **(60, 8)**  
> 60ê°œì˜ ì‹œê³„ì—´ step Ã— 8ê°œ feature

---

### ì¶œë ¥ ë°ì´í„° (output)

| ë³€ìˆ˜ëª…  | ì˜ë¯¸              | ì‹œê°„ í•´ìƒë„ | ì‹œê³„ì—´ ê¸¸ì´ |
|---------|-------------------|--------------|--------------|
| Tbdy    | ì‹¤ë‚´ ì˜¨ë„ (ì˜ˆì¸¡)  | 30ì´ˆ        | 10ê°œ (5ë¶„)   | 

> ì¶œë ¥ì€ 30ì´ˆ ê°„ê²©ìœ¼ë¡œ ë¯¸ë˜ 5ë¶„ê°„ì˜ ì‹¤ë‚´ì˜¨ë„(Tbdy) ì˜ˆì¸¡  
> ëª¨ë¸ ì¶œë ¥ í˜•íƒœ: **(10,1)**

---
24ë…„ 9ì›” 3ì¼ ê²½ë‚¨ì‚¬ë¬´ì‹¤ ë°ì´í„°ë¥¼ ì´ìš©í•˜ì—¬ í•™ìŠµ 

### ëª¨ë¸ íŒŒë¼ë¯¸í„°
```
íˆë“  ìŠ¤í…Œì´íŠ¸ 64 ì°¨ì›

ì—í¬í¬ 30~50 

loss function: MSE
```

## ëª¨ë¸ ì„±ëŠ¥ ê²°ê³¼
### ê²½ë‚¨ ì‚¬ë¬´ì‹¤ 9ì›” 3ì¼ ë°ì´í„°ë¡œ ëª¨ë¸ í…ŒìŠ¤íŠ¸ ê²°ê³¼
![0903_1](images/0903ì˜ˆì‹œ1.png)
![0903_2](images/0903ì˜ˆì‹œ2.png)
![0903_3](images/0903ì˜ˆì‹œ3.png)

### ê²½ë‚¨ ì‚¬ë¬´ì‹¤ 9ì›” 4ì¼ ë°ì´í„°ë¡œ ëª¨ë¸ í…ŒìŠ¤íŠ¸ ê²°ê³¼
![0904_1](images/0904ì˜ˆì‹œ1.png)
![0904_2](images/0904ì˜ˆì‹œ2.png)
![0904_3](images/0904ì˜ˆì‹œ3.png)

### ê³µëŒ€ 7í˜¸ê´€ 4ì›” 28ì¼ ë°ì´í„°ë¡œ ëª¨ë¸ í…ŒìŠ¤íŠ¸ ê²°ê³¼
![0428_1](images/ê³µëŒ€7í˜¸ê´€ì˜ˆì‹œ1.png)
![0428_2](images/ê³µëŒ€7í˜¸ê´€ì˜ˆì‹œ2.png)
![0428_3](images/ê³µëŒ€7í˜¸ê´€ì˜ˆì‹œ3.png)


9ì›” 3ì¼ ê²½ë‚¨ ì‚¬ë¬´ì‹¤ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•™ìŠµí•œ ëª¨ë¸ì€ í•´ë‹¹ ë‚ ì§œì— ëŒ€í•´ ìš°ìˆ˜í•œ ì˜ˆì¸¡ ì„±ëŠ¥ì„ ë³´ì˜€ê³  9ì›” 4ì¼ ë°ì´í„°ì—ì„œë„ ì„±ëŠ¥ì´ ì•ˆì •ì ìœ¼ë¡œ ìœ ì§€ë˜ì—ˆë‹¤. 

ê·¸ëŸ¬ë‚˜ 4ì›” 28ì¼ ê³µëŒ€ 7í˜¸ê´€ ë°ì´í„°ì— ëŒ€í•´ ì˜ˆì¸¡í•œ ê²°ê³¼, ì „ë°˜ì ì¸ ê²½í–¥ì„±ì€ ë”°ë¼ ê°”ìœ¼ë‚˜ ì˜¨ë„ ì˜ˆì¸¡ê°’ì´ ì‹¤ì œë³´ë‹¤ ë†’ê²Œ ë‚˜íƒ€ë‚¬ìœ¼ë©°, ì´ëŠ” ê³„ì ˆì  íŠ¹ì„±ì´ ë°˜ì˜ë˜ì§€ ì•Šì•˜ìŒì„ ì˜ë¯¸í•œë‹¤. 

ë”°ë¼ì„œ ë³´ë‹¤ ì¼ë°˜í™”ëœ ì˜ˆì¸¡ ì„±ëŠ¥ì„ í™•ë³´í•˜ê¸° ìœ„í•´ì„œëŠ” ë‹¤ì–‘í•œ ì›”ë³„ ë°ì´í„°ë¥¼ í¬í•¨í•œ í•™ìŠµì´ í•„ìš”í•¨ì„ ì˜ë¯¸í•œë‹¤.



## ì‚¬ìš©í•œ ì½”ë“œ
### ë³€ìˆ˜ë“¤ ê°„ ìƒê´€ê´€ê³„ ë¶„ì„
```py
# êµ¬ê¸€ ì½”ë©ìš©: íŒŒì¼ ì—…ë¡œë“œ ë¼ì´ë¸ŒëŸ¬ë¦¬ í˜¸ì¶œ
from google.colab import files
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# íŒŒì¼ ì—…ë¡œë“œ
uploaded = files.upload()

# ì—…ë¡œë“œëœ íŒŒì¼ ì½ê¸°
# uploadedì€ ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¼ key()ë¡œ íŒŒì¼ ì´ë¦„ ê°€ì ¸ì˜¬ ìˆ˜ ìˆìŒ
filename = list(uploaded.keys())[0]
df = pd.read_csv(filename)

# ì‚¬ìš©í•  ì»¬ëŸ¼ë§Œ ì„ íƒ
features = ['Thmo On', 'Tcon', 'Frun', 'Tpip_in', 'Tpip_out', 'Tod', 'Power', 'Tbdy']
df_selected = df[features]

# ìƒê´€ê³„ìˆ˜ ê³„ì‚°
corr_matrix = df_selected.corr()

# íˆíŠ¸ë§µ ì‹œê°í™”
plt.figure(figsize=(10, 8))
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f')
plt.title('Feature Correlation Heatmap')
plt.show()
```



### CSV íŒŒì¼ ì—…ë¡œë“œ ë° ë°ì´í„° ì¤€ë¹„
```PY
from google.colab import files
import pandas as pd
import numpy as np

# íŒŒì¼ ì—…ë¡œë“œ
uploaded = files.upload()

# íŒŒì¼ ì½ê¸°
filename = list(uploaded.keys())[0]
df = pd.read_csv(filename)

# ì‚¬ìš©í•  ì»¬ëŸ¼ ì„ íƒ
features = ['Auto Id', 'Thmo On', 'Tcon', 'Frun', 'Tpip_in', 'Tpip_out', 'Tod', 'Power', 'Tbdy']
df = df[features]

# ê²°ì¸¡ì¹˜ ì²˜ë¦¬ (ê°„ë‹¨íˆ ë“œë)
df = df.dropna()

# ì •ê·œí™” (MinMaxScaler)
from sklearn.preprocessing import MinMaxScaler

scaler = MinMaxScaler()
# Auto idëŠ” ì •ê·œí™”ì—ì„œ ì œì™¸
df_scaled = df.copy()
df_scaled[df.columns[1:]] = scaler.fit_transform(df[df.columns[1:]])
```

### ë°ì´í„°ì…‹ ì •ì˜
```py
from torch.utils.data import Dataset, DataLoader
import torch

class HVACDatasetV2(Dataset):
    def __init__(self, data, input_window, output_window, stride, output_stride):
        self.data = data
        self.input_window = input_window
        self.output_window = output_window
        self.stride = stride
        self.output_stride = output_stride
        self.X, self.Y = self.create_sequences()

    def create_sequences(self):
        X = []
        Y = []
        for auto_id, group in self.data.groupby('Auto Id'):
            group = group.drop(columns=['Auto Id']).values
            L = len(group)
            for i in range(0, L - self.input_window - self.output_window * self.output_stride, self.stride):
                x_seq = group[i:i+self.input_window, :]
                # output_stride ë§Œí¼ ê±´ë„ˆë›´ Tbdy ì˜ˆì¸¡
                y_seq = group[i+self.input_window : i+self.input_window+self.output_window*self.output_stride : self.output_stride, -1]
                X.append(x_seq)
                Y.append(y_seq)
        return torch.tensor(X, dtype=torch.float32), torch.tensor(Y, dtype=torch.float32)


    def __len__(self):
        return len(self.X)

    def __getitem__(self, idx):
        return self.X[idx], self.Y[idx]
```

### ë°ì´í„° ì¤€ë¹„
```py
# í•˜ì´í¼íŒŒë¼ë¯¸í„°
input_window = 60
output_window = 10
stride = 1
output_stride = 6

# ìƒˆë¡œ ë§Œë“  ë°ì´í„°ì…‹ í´ë˜ìŠ¤ í™œìš©
dataset = HVACDatasetV2(df_scaled, input_window, output_window, stride, output_stride)

# í•™ìŠµ/ê²€ì¦ ë¶„í• 
train_size = int(0.8 * len(dataset))
val_size = len(dataset) - train_size
train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])

# ë°ì´í„°ë¡œë” ìƒì„±
batch_size = 64
train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)
```

### LSTM ì¸ì½”ë” ë””ì½”ë” ëª¨ë¸
```PY
import torch.nn as nn

class Encoder(nn.Module):
    def __init__(self, input_dim, hidden_dim, num_layers=1):
        super(Encoder, self).__init__()
        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)

    def forward(self, x):
        outputs, (hidden, cell) = self.lstm(x)
        return hidden, cell

class Decoder(nn.Module):
    def __init__(self, hidden_dim, output_dim, num_layers=1):
        super(Decoder, self).__init__()
        self.lstm = nn.LSTM(hidden_dim, hidden_dim, num_layers, batch_first=True)
        self.fc = nn.Linear(hidden_dim, output_dim)

    def forward(self, hidden, cell, output_len):
        batch_size = hidden.size(1)
        outputs = []
        input_step = torch.zeros((batch_size, 1, hidden.size(2))).to(hidden.device)  # ì œë¡œ ì…ë ¥
        for _ in range(output_len):
            output, (hidden, cell) = self.lstm(input_step, (hidden, cell))
            pred = self.fc(output.squeeze(1))  # (batch, output_dim)
            outputs.append(pred.unsqueeze(1))
            input_step = output
        outputs = torch.cat(outputs, dim=1)  # (batch, output_len, output_dim)
        return outputs

class LSTMSeq2Seq(nn.Module):
    def __init__(self, input_dim, hidden_dim, output_len):
        super(LSTMSeq2Seq, self).__init__()
        self.encoder = Encoder(input_dim, hidden_dim)
        self.decoder = Decoder(hidden_dim, 1)
        self.output_len = output_len

    def forward(self, src):
        hidden, cell = self.encoder(src)
        output = self.decoder(hidden, cell, self.output_len)
        return output.squeeze(-1)  # (batch, output_len)
```

### í•™ìŠµ ì„¤ì •
```PY
# ë””ë°”ì´ìŠ¤ ì„¤ì •
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# ëª¨ë¸ ìƒì„±
input_dim = 8  # ì…ë ¥ í”¼ì²˜ ê°œìˆ˜
hidden_dim = 64
output_len = output_window

model = LSTMSeq2Seq(input_dim, hidden_dim, output_len).to(device)

# ì†ì‹¤í•¨ìˆ˜ì™€ ì˜µí‹°ë§ˆì´ì €
criterion = nn.MSELoss()
optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)
```

### í•™ìŠµ ë£¨í”„
```PY
from tqdm import tqdm
import matplotlib.pyplot as plt

n_epochs = 50
train_losses = []
val_losses = []

for epoch in range(n_epochs):
    model.train()
    train_loss = 0

    # tqdm progress bar
    loop = tqdm(train_loader, desc=f"Epoch {epoch+1}/{n_epochs}", leave=False)
    for X_batch, Y_batch in loop:
        X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)
        optimizer.zero_grad()
        output = model(X_batch)
        loss = criterion(output, Y_batch)
        loss.backward()
        optimizer.step()
        train_loss += loss.item()
        loop.set_postfix(loss=loss.item())

    avg_train_loss = train_loss / len(train_loader)
    train_losses.append(avg_train_loss)

    model.eval()
    val_loss = 0
    with torch.no_grad():
        for X_batch, Y_batch in val_loader:
            X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)
            output = model(X_batch)
            loss = criterion(output, Y_batch)
            val_loss += loss.item()

    avg_val_loss = val_loss / len(val_loader)
    val_losses.append(avg_val_loss)

    print(f"[{epoch+1}/{n_epochs}] Train Loss: {avg_train_loss:.6f} | Val Loss: {avg_val_loss:.6f}")
```

### ì†ì‹¤ ì‹œê°í™”
```py
# ëª¨ë¸ì„ evaluation ëª¨ë“œë¡œ ì „í™˜
model.eval()

# ê²€ì¦ ë°ì´í„°ì…‹ì—ì„œ í•˜ë‚˜ì˜ ë°°ì¹˜ë¥¼ ê°€ì ¸ì˜¤ê¸°
X_batch, Y_batch = next(iter(val_loader))
X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)

# ì˜ˆì¸¡
with torch.no_grad():
    y_pred = model(X_batch)  # (batch_size, output_len)

# CPUë¡œ ì˜®ê¸°ê³  numpy ë³€í™˜
y_pred = y_pred.cpu().numpy()
y_true = Y_batch.cpu().numpy()

import random
# í•˜ë‚˜ì˜ ìƒ˜í”Œë§Œ ì„ íƒ
sample_idx = random.randint(0, y_pred.shape[0] - 1)
predicted = y_pred[sample_idx]      # ì •ê·œí™”ëœ ì˜ˆì¸¡
ground_truth = y_true[sample_idx]   # ì •ê·œí™”ëœ ì‹¤ì œ

# 30ì´ˆ ê°„ê²© ì‹œê°„ì¶• ìƒì„±
time_axis = np.arange(30, 30 * (len(ground_truth) + 1), 30)

# âœ… ì •ê·œí™” í•´ì œ (TbdyëŠ” ë§ˆì§€ë§‰ featureì´ë¯€ë¡œ ì—´ index = -1)
# scalerëŠ” ì›ë˜ ì „ì²´ feature (8ê°œ)ì— ëŒ€í•´ fit ë˜ì—ˆìœ¼ë¯€ë¡œ, Tbdyë§Œ ë³µì›í•´ì•¼ í•¨

tbdy_min = scaler.data_min_[-1]
tbdy_max = scaler.data_max_[-1]

predicted_real = predicted * (tbdy_max - tbdy_min) + tbdy_min
ground_truth_real = ground_truth * (tbdy_max - tbdy_min) + tbdy_min

# âœ… Plot
import matplotlib.pyplot as plt

plt.figure(figsize=(10, 5))
plt.plot(time_axis, ground_truth_real, label='Ground Truth Tbdy (Â°C)', marker='o')
plt.plot(time_axis, predicted_real, label='Predicted Tbdy (Â°C)', marker='x')
plt.xlabel('Prediction Horizon (Seconds)')
plt.ylabel('Tbdy (Â°C)')
plt.title('Predicted vs Ground Truth Tbdy (Denormalized, 30s Interval)')
plt.ylim(tbdy_min - 1, tbdy_max + 1)  # yì¶• í™•ëŒ€
plt.legend()
plt.grid(True)
plt.show()
```

### ë‹¤ë¥¸ ë‚ ì§œ ë¶ˆëŸ¬ì˜¤ê¸° ë° ì „ì²˜ë¦¬
```PY
from google.colab import files
import pandas as pd

# ğŸ“‚ 1. íŒŒì¼ ì—…ë¡œë“œ
uploaded = files.upload()  # íŒŒì¼ ì—…ë¡œë“œ ì°½ì´ ëœ¸

# ğŸ“„ 2. ì—…ë¡œë“œëœ íŒŒì¼ëª… ì¶”ì¶œ
filename = list(uploaded.keys())[0]

# ğŸ“Š 3. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
new_df = pd.read_csv(filename)

# âœ… 4. Feature ì„ íƒ ë° ê²°ì¸¡ì¹˜ ì œê±°
features = ['Auto Id', 'Thmo On', 'Tcon', 'Frun', 'Tpip_in', 'Tpip_out', 'Tod', 'Power', 'Tbdy']
new_df = new_df[features].dropna()

# ğŸ”„ 5. ê¸°ì¡´ scalerë¥¼ ì‚¬ìš©í•˜ì—¬ ì •ê·œí™”
new_df_scaled = new_df.copy()
new_df_scaled[new_df.columns[1:]] = scaler.transform(new_df[new_df.columns[1:]])
```
### ìƒˆë¡œìš´ ë°ì´í„°ì…‹ ìƒì„±
```py
new_dataset = HVACDatasetV2(
    new_df_scaled,
    input_window=60,
    output_window=10,
    stride=1,
    output_stride=6
)

new_loader = DataLoader(new_dataset, batch_size=64, shuffle=False)
```

### ëª¨ë¸ ì˜ˆì¸¡ ë° ì„±ëŠ¥ê²€ì¦
```py
from sklearn.metrics import mean_absolute_error, mean_squared_error
import numpy as np
import matplotlib.pyplot as plt

# 1. ëª¨ë¸ í‰ê°€ ëª¨ë“œ
model.eval()
all_preds = []
all_trues = []

# 2. ë°°ì¹˜ë³„ ì˜ˆì¸¡ ìˆ˜ì§‘
with torch.no_grad():
    for X_batch, Y_batch in new_loader:
        X_batch = X_batch.to(device)
        Y_batch = Y_batch.to(device)

        pred = model(X_batch)
        all_preds.append(pred.cpu().numpy())
        all_trues.append(Y_batch.cpu().numpy())

# 3. ì „ì²´ ë³‘í•©
preds = np.concatenate(all_preds, axis=0)  # (ì „ì²´ ìƒ˜í”Œ ìˆ˜, output_len)
trues = np.concatenate(all_trues, axis=0)

# 4. ì •ê·œí™” í•´ì œ
tbdy_index = new_df.columns[1:].get_loc('Tbdy')
tbdy_min = scaler.data_min_[tbdy_index]
tbdy_max = scaler.data_max_[tbdy_index]

preds_real = preds * (tbdy_max - tbdy_min) + tbdy_min
trues_real = trues * (tbdy_max - tbdy_min) + tbdy_min

# 5. ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°
mae = mean_absolute_error(trues_real.flatten(), preds_real.flatten())
mse = mean_squared_error(trues_real.flatten(), preds_real.flatten())
rmse = np.sqrt(mse)

print(f"New Data Evaluation â€” MAE: {mae:.4f} Â°C, RMSE: {rmse:.4f} Â°C")

import random
# 6. ì‹œê°í™” (0ë²ˆì§¸ ìƒ˜í”Œì„ ì˜ˆì‹œë¡œ ì¶œë ¥)
sample_idx = random.randint(0, len(preds_real) - 1)
pred_sample = preds_real[sample_idx]    # (output_len,)
true_sample = trues_real[sample_idx]    # (output_len,)

# ì‹œê°„ì¶• ìƒì„±: 30ì´ˆ ê°„ê²©, ì˜ˆì¸¡ ìŠ¤í… ìˆ˜ë§Œí¼
time_axis = np.arange(30, 30 * (len(true_sample) + 1), 30)

# 7. Plot
plt.figure(figsize=(10, 5))
plt.plot(time_axis, true_sample, label='Ground Truth Tbdy (Â°C)', marker='o')
plt.plot(time_axis, pred_sample, label='Predicted Tbdy (Â°C)', marker='x')
plt.xlabel('Prediction Horizon (Seconds)')
plt.ylabel('Tbdy (Â°C)')
plt.title(f'Prediction vs Ground Truth on New Data (Sample #{sample_idx})\nMAE: {mae:.3f} Â°C, RMSE: {rmse:.3f} Â°C')
plt.ylim(tbdy_min - 1, tbdy_max + 1)
plt.grid(True)
plt.legend()
plt.show()
```


## í•™ìŠµí•œ ëª¨ë¸ Localì— ë‹¤ìš´ë¡œë“œ
### ë‚´ ì»´í“¨í„°ë¡œ ë‹¤ìš´ë¡œë“œ
```py
# 1. ëª¨ë¸ ì €ì¥
torch.save(model.state_dict(), "lstm_seq2seq_tbdy_model.pt")

# 2. í™•ì¸
import os
print("Saved files:", os.listdir())

# 3. ë‹¤ìš´ë¡œë“œ
from google.colab import files
files.download("lstm_seq2seq_tbdy_model.pt")
```

### Colabì—ì„œ ë¡œì»¬ ëª¨ë¸ íŒŒì¼ ì—…ë¡œë“œí•˜ì—¬ ë¶ˆëŸ¬ì˜¤ê¸°
```py
from google.colab import files
uploaded = files.upload()  # íŒŒì¼ ì—…ë¡œë“œ ì°½ì´ ëœ¸

# ì˜ˆ: lstm_seq2seq_tbdy_model.pt ì—…ë¡œë“œí–ˆë‹¤ê³  ê°€ì •
model.load_state_dict(torch.load("lstm_seq2seq_tbdy_model.pt"))
model.eval()
```